# marketplace_matching

## Структура репозитория
- /app - папка с приложением и докер-файлом для сборки. После запуска приложение работает по адресу localhost:8010, принимает на вход файл со строкой с вектором признаков, перечисленных через пробел (72 признака), выполняет для него предобработку и выдает 5 наиболее подходящих кандидатов из базы данных. Для демонстрации используется уменьшенный набор индексов в базе данных.
- matching_part_1.ipynb, matching_part_2.ipynb - ноутбуки с экспериментами
- matching_batch.ipynb - эксперименты с обучением моделей бустинга на подвыборках
- /img - изображения
- /example - папка с тестовыми файлами примеров
- mathing_final.pdf - финальная презентация
__________________

## Постановка задачи
Есть набор данных по товарам интернет-магазина (почти 3,000,000 товаров). Данные представлены в обезличенном виде. Есть тренировочная выборка с набором данных по похожим товарам и разметкой, какому товару из главной базы данных соответствуюет товар из тренировочной выборки. И есть валидационная выборка, аналогичная тестовой по структуре, но без разметки. Разметка валидационной выборки дана в отдельном файле.

|Датасет|Описание|Количество строк|
|---|---|---|
|train|обучающая выборка|100,000|
|valid|валидационная выборка|100,000|
|answers|разметка для валидационной выборки|100,000|
|base|Общая база данных по всем товарам|>2,900,000|

**Требуется**

Построить модель, выдающую по запросу из выборки valid 5 наиболее релевантных товаров из выборки base

**Целевая метрика**

Accuracy@5 (в идеале - требуется добиться 80%)

## План исследования
_______
- анализ и предобработка данных
- грубый поиск нескольких десятков/сотен кандидатов (FAISS и nmslib)
- точный поик 5 наиболее релевантных кандидатов (CatBoost, Logistic Regression)
- расчет целевой метрики

## Принятые допущения
_______
В экспериментах датасет разбит на батчи: размер обучающего - 10000 записей, размер валидационного - 5000 записей. Показана работа модели для первого батча.

## Анализ и предобработка
________
**Анализ**
- пропусков и явных дубликатов в данных нет
- все значения, кроме таргетов, имеют тип float
- корреляции между признаками практически нет (см. рисунок 1)
- Практически все признаки распределены нормально (см. рисунок 2)
- некоторые признаки (21, 25, 70) по сути являются константами (одинаковы для всех векторов) (рисунок 3)
  
<img src="https://github.com/fedor-konovalenko/marketplace_matching/blob/main/img/heatmap.png" width="500" height="500">

*Рисунок 1*

<img src="https://github.com/fedor-konovalenko/marketplace_matching/blob/main/img/hist_1.png" width="500" height="500">

*Рисунок 2*

<img src="https://github.com/fedor-konovalenko/marketplace_matching/blob/main/img/hist_25.png" width="500" height="500">

*Рисунок 3*

**Предобработка**
- масштабирование
- удаление константных признаков

## Грубый поиск
_____________

### [NMSLIB](https://github.com/nmslib/nmslib)

В основе этой библиотеки лежат иерархические графы и поиск кратчайших расстояний на плоскости по ребрам графа. 
Для 100 ближайших соседей не удалось добиться точности более 0,5. Кроме того, эта библиотека не поддерживает работу с GPU, соответственно, время поиска сильно возрастает

### [FAISS](https://faiss.ai/index.html)

Эта библиотека основана на идее разделения плоскости на кластеры и поиска соседей в пределах кластера.
Для нее были исследованы различные способы индексирования соседей, различное количество кластеров и соседей, а также работа на CPU или GPU
Также исследовалась точность на данных с удаленными и неудаленными константными признаками, так удаление признаков, повысило точность на 2%.

**CPU**
---
**IndexFlatL2**

| n_cells | n_neibourghs | result |
|---|---|---|
|20|10|0,6|
|20|100|0,65|
|200|10|0,59|
|200|100|0,65|

**IndexFlatIP**

| n_cells | n_neibourghs | result |
|---|---|---|
|20|10|0,6|
|20|100|0,68|
|200|10|0,6|
|200|100|0,65|

**IndexFlatIVFPQ**

| n_cells | n_neibourghs | result |
|---|---|---|
|20|10|0,35|
|20|100|0,46|
|200|10|0,43|
|200|100|0,56|

**Видно, что наилучшие результаты достигаются для 200 центроид и от 100 соседей**

**GPU**
---

| n_cells | n_neibourghs | Index | result |
|---|---|---|---|
|200|20|IndexFlatL2| 0,73|
|200|20|IndexFlatIp|0,71|
|200|100|IndexFlatL2| 0,79|
|200|100|IndexFlatIp|0,78|
|200|200|IndexFlatL2| 0,81|
|200|200|IndexFlatIp|0,80|

**Промежуточный вывод. Чтобы приблизиться к целевой метрике, на следующем этапе выбора 5 ближайших соседей из 100 или 200 кандидатов точность должна быть близка к 100%.**
## Точный поиск
______________
Далее после грубого поиска найденные кандидаты и присвоенные им метки класса (соответствует/не соответствует) собирались в массив и передавались на вход одной из моделей машинного обучения.
После обучения модели передавалась валидационная выборка и предсказывалась вероятность принадлежности к одному из двух классов для каждого кандидата. Далее 5 наиболее вероятных кандидатов для каждого запроса из валидационной выборки считались ответом, и на основании этого рассчитывались метрика

| Модель|Accuracy@100 |Accuracy@5 |Примечание |
|---|---|---|---|
|LogisticRegression|0,74|0,09|Явно видно переобучение на слишком большом количестве признаков|
|LogisticRegresiion (n_features=1)|0,74|0,68|В качестве единственного признака использовалось расстояние между векторами. найденное в FAISS|
|CatBoostRanker|0,74|0,67|Вероятнее всего, я использовал его неправильно, поскольку специфичные для него метрики не работали|
|CatBoostClassifier|0,74|0,68|Нужно будет повысить точность в FAISS и попробовать менять гиперпараметры|

**Upd:**
| Модель|Accuracy@20 |Accuracy@5 |
|---|---|---|
|LogisticRegression|0,73|0,33|
|LogisticRegresiion (n_features=1)|0,73|0,68|
|CatBoostRanker|0,73|0,68|
|CatBoostClassifier|0,73|0,70|

## Выводы

Цели и задачи в дальнейшем
- повысить точность грубого поиска
- подобрать оптимальное количество кандидатов и гиперпараметры точного поиска
- изменить модель точного поиска в приложении (сейчас- это логистическая регрессия, использующая один признак)
- ~~доделать потоковую загрузку данных, обучение и валидацию~~ **Upd - сделано**

